<!--Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可-->

## 17.2 卷积前向计算代码实现

### 17.2.1 卷积核的实现

卷积核，实际上和全连接层一样，是权重矩阵加偏移向量的组合，区别在于全连接层中的权重矩阵是二维的，偏移矩阵是列向量，而卷积核的权重矩阵是四维的，偏移矩阵是也是列向量。<font color=red> ToDo: 全连接层的权重矩阵是二维的？我以为是一维的？再过一下代码？ </font>

```Python
class ConvWeightsBias(WeightsBias_2_1):
    def __init__(self, output_c, input_c, filter_h, filter_w, init_method, optimizer_name, eta):
        self.FilterCount = output_c
        self.KernalCount = input_c
        self.KernalHeight = filter_h
        self.KernalWidth = filter_w
        ...

    def Initialize(self, folder, name, create_new):
        self.WBShape = (self.FilterCount, self.KernalCount, self.KernalHeight, self.KernalWidth)        
        ...
```
<img src="../Images/17/ConvWeightsBias.png" />

图17-19 卷积核的组成

以图17-19为例，各个维度的数值如下：

- FilterCount=2，第一维，过滤器数量，对应输出通道数。
- KernalCount=3，第二维，卷积核数量，对应输入通道数。两个Filter里面的Kernal数必须相同。
- KernalHeight=5，KernalWidth=5，卷积核的尺寸，第三维和第四维。同一组WeightsBias里的卷积核尺寸必须相同。

<font color=green> 这里就是给出了卷积核的权重矩阵是四维的解释；另外，需要注意的是，这个每一个filter中的kernal必须是相同的；同时呢，就是这个每一组（就是filter 1的第1个kernal和filter 2的第2个kernal）的kernal的维度是必须相同的。</font>

<font color=red> ToDo: 我对这个“同一组WeightsBias”的概念有点模糊，不过我现在更加倾向于一个filter中的所有keral是同一个组的概念。</font>

在初始化函数中，会根据四个参数定义`WBShape`，然后在`CreateNew`函数中，创建相应形状的`Weights`和`Bias`。

### 17.2.2 卷积前向运算的实现 - 方法1
```Python
class ConvLayer(CLayer):
    def forward(self, x, train=True):
        self.x = x
        self.batch_size = self.x.shape[0] # 这个我暂时没有看明白-->我的理解，这里x的输入，仅仅是一个batch
        # 如果有必要的话，先对输入矩阵做padding
        if self.padding > 0:
            self.padded = np.pad(...)
        else:
            self.padded = self.x
        #end if
        self.z = conv_4d(...)
        return self.z
```

上述代码中的`conv_4d()`函数实现了17.1中定义的四维卷积运算：

```Python
def conv_4d(x, weights, bias, out_h, out_w, stride=1):
    batch_size = x.shape[0]
    input_channel = x.shape[1]
    output_channel = weights.shape[0]
    filter_height = weights.shape[2]
    filter_width = weights.shape[3]
    rs = np.zeros((batch_size, num_output_channel, out_h, out_w))

    for bs in range(batch_size):
        for oc in range(output_channel): # filter的数量
            rs[bs,oc] += bias[oc] # 这里对得到了三个feature进行就和的操作
            for ic in range(input_channel): # filter中kernal的数量
                for i in range(out_h): # 输出feature高度
                    for j in range(out_w): # 输出feature宽度
                        ii = i * stride
                        jj = j * stride
                        for fh in range(filter_height):
                            for fw in range(filter_width):
                                rs[bs,oc,i,j] += x[bs,ic,fh+ii,fw+jj] * weights[oc,ic,fh,fw] # (5) in Section 17.1
```

上面的函数包含以下几重循环：

1. 批量数据循环（第一维）：`bs in batch_size`，对每个样本进行计算；
2. 输出通道循环（第二维）：`oc in output_channel`。这里先把`bias`加上了，后加也可以；
3. 输入通道循环：`ic in input_channel`;
4. 输出图像纵坐标循环：`i in out h`；
5. 输出图像横坐标循环：`j in out_w`。循环4和5完成对输出图像的每个点的遍历，在下面的子循环中计算并填充值；
6. 卷积核纵向循环（第三维）：`fh in filter_height`；
7. 卷积核横向循环（第四维）：`fw in filter_width`。循环6和7完成卷积核与输入图像的卷积计算，并保存到循环4和5指定的输出图像的点上。

<font color=green> 上面实现四维卷积运算的代码确实是非常的巧妙的，这个确实是需要深刻的理解之后，才能够完成这件事情的程序实现的。这里需要注意的是，如果上面最后一行代码不是特别得看的明白的话，可以参照Section 17.1的图17.16，放几组数据进去之后，就是可以明白这行公式的意义了。</font>

我们试着运行上面的代码并循环10次，看看它的执行效率如何：

```
Time used for Python: 38.057225465774536
```

出乎我们的预料，在足足等了30多秒后，才返回结果。

通过试验发现，其运行速度非常慢，如果这样的函数在神经网络训练中被调用几十万次，其性能是非常糟糕的，这也是`Python`做为动态语言的一个缺点。<font color=green> 好吧，之前计算bada数据的时候，就是一直是发现这个速度是非常的慢的，看到这里，终于明白了，这个算是`Python`的一个缺点。</font>

<font color=green>----------

对于静态语言（强类型语言）：静态语言是在编译时变量的数据类型即可确定的语言，多数静态类型语言要求在使用变量之前必须声明数据类型。例如：C++、C等。
对于动态语言（弱类型语言）：动态语言是在运行时确定数据类型的语言。变量使用之前不需要类型声明，通常变量的类型是被赋值的那个值的类型。例如：Python等。

---------- </font >

### 17.2.3 卷积前向运算的实现 - 方法2

既然动态语言速度慢，我们把它编译成静态方法，是不是会快一些呢？<font color=green> 这里就是给出了一个让Python中某一些关键的方程运行速度更快的方式了，这个倒是可以借鉴使用的（但是我还是不建议使用这一种的方式的了，如果python本身就是有更好的解决方法，还是以python方式为主的了。）</font>

很幸运，有这样一个开源项目：[numba](https://numba.pydata.org/)，它可以在运行时把`Python`编译成`C`语言执行，代码是用`C`语言“风格”编写的`Python`代码，而且越像`C`的话，执行速度越快。

我们先用`pip`安装`numba`包：

```
pip install numba
```

<font color=green> conda安装也是可以的，不过是在conda-forge这个channel下面了。</font>

然后在需要运行时编译的函数前面加上一个装饰符：

```Python
@nb.jit(nopython=True)
def jit_conv_4d(x, weights, bias, out_h, out_w, stride=1):
    ...
```

为了明确起见，我们把`conv_4d`前面加上一个`jit`前缀，表明这个函数是经过`numba`加速的。然后运行循环10次的测试代码：

```
Time used for Numba: 0.0727994441986084
```

又一次出乎我们的预料，这次只用了0.07秒，比纯`Python`代码快了500多倍！

但是不要急，我们还需要检查一下其正确性。方法1输出结果为`output1`，Numba编译后的方法输出结果为`output2`，二者都是四维矩阵，我们用`np.allclose()`函数来比较它们的差异：

```Python
    print("correctness:", np.allclose(output1, output2, atol=1e-7))
```

得到的结果是：

```
correctness: True
```

`np.allclose`方法逐元素检查两种方法的返回值的差异，如果绝对误差在`1e-7`之内，说明两个返回的四维数组相似度极高，运算结果可信。

<font color=green> 比较两个array是否相同。可以使用这个api</font>

为什么不把所有的Python代码都编译成C代码呢？是因为`numba`的能力有限，并不支持`numpy`的所有函数，所以只能把关键的运算代码设计为独立的函数，然后用`numba`编译执行，函数的输入可以是数组、向量、标量，不能是复杂的自定义结构体或函数指针。<font color=green> 这个`numba`也是仅仅是针对特定的变量，比如说数据，向量，标量而言，其他的变量（比如指针）就是不太行了</font>

### 17.2.4 卷积前向运算的实现 - 方法3

由于卷积操作是原始图片数据与卷积核逐点相乘的结果，所以遍历每个点的运算速度非常慢。在全连接层中，由于是两个矩阵直接相乘，所以速度非常快。我们是否可以把卷积操作转换为矩阵操作呢？

在Caffe框架中，巧妙地把逐点相乘的运算转换成了矩阵运算，大大提升了程序运行速度。这就是著名的`im2col`函数（我们在代码中命名为`img2col`)。

```Python
    def forward_img2col(self, x, train=True):
        self.x = x
        self.batch_size = self.x.shape[0]
        assert(self.x.shape == (self.batch_size, self.InC, self.InH, self.InW))
        self.col_x = img2col(x, self.FH, self.FW, self.stride, self.padding)
        self.col_w = self.WB.W.reshape(self.OutC, -1).T
        self.col_b = self.WB.B.reshape(-1, self.OutC)
        out1 = np.dot(self.col_x, self.col_w) + self.col_b
        out2 = out1.reshape(batch_size, self.OutH, self.OutW, -1)
        self.z = np.transpose(out2, axes=(0, 3, 1, 2))
        return self.z
```

#### 原理

我们观察一下图17-20。

<img src="../Images/17/img2col.png" ch="500" />

图17-20 把卷积运算转换成矩阵运算

先看上半部分：绿色的$3\times 3$矩阵为输入，经过棕色的卷积核运算后，得到右侧的$2\times 2$的矩阵。

再看图的下半部分：

第一步，上半部分中蓝色的虚线圆内的四个元素排列成第1行，形成[0,1,3,4]，红色虚线圆内的四个元素排列成第4行[4,5,7,8]，中间两行可以从右上角的[1,2,4,5]和左下角的[3,4,6,7]得到。这样，一个$3\times 3$的矩阵，就转换成了一个$4\times 4$的矩阵。也就是把卷积核视野中的每个二维$2\times 2$的数组变成$1\times 4$的向量。

第二步，把棕色的权重矩阵变成$4\times 1$的向量[3,2,1,0]。<font color=green> 第一步中每一个1x4的向量乘以第二个步骤中4x1的向量，就是一个1x1的标量；另外，第一步&二步中这么变量的原因，也是因为矩阵变换（可以得到想要的结构）</font>

第三步，把$4\times 4$的矩阵与$4\times 1$的向量相乘，得到$4\times 1$的结果向量[5,11,23,29]。

第四步：把$4\times 1$的结果变成$2\times 2$的矩阵，就得到了卷积运算的真实结果。

#### 四维数组的展开

前面只说明了二维数组的展开形式，四维数组可以用同样的方式展开。

我们假定有2个输入样本，每个样本含有3个通道，每个通道上是$3\times 3$的数据，则样本的原始形状和展开形状分别是：
```
x =
(样本1)                 [样本2]
    (通道1)                 (通道1)
 [[[[ 0  1  2]           [[[27 28 29]
   [ 3  4  5]              [30 31 32]
   [ 6  7  8]]             [33 34 35]]
    (通道2)                 (通道2)
  [[ 9 10 11]             [[36 37 38]
   [12 13 14]              [39 40 41]
   [15 16 17]]             [42 43 44]]
    (通道3)                 (通道3)
  [[18 19 20]             [[45 46 47]
   [21 22 23]              [48 49 50]
   [24 25 26]]]            [51 52 53]]]]
------------------------------------------   
col_x =
 [[0.  1.  3.  4.|  9. 10. 12. 13.| 18. 19. 21. 22.]
 [ 1.  2.  4.  5.| 10. 11. 13. 14.| 19. 20. 22. 23.]
 [ 3.  4.  6.  7.| 12. 13. 15. 16.| 21. 22. 24. 25.]
 [ 4.  5.  7.  8.| 13. 14. 16. 17.| 22. 23. 25. 26.]
 ----------------+----------------+----------------
 [27. 28. 30. 31.| 36. 37. 39. 40.| 45. 46. 48. 49.]
 [28. 29. 31. 32.| 37. 38. 40. 41.| 46. 47. 49. 50.]
 [30. 31. 33. 34.| 39. 40. 42. 43.| 48. 49. 51. 52.]
 [31. 32. 34. 35.| 40. 41. 43. 44.| 49. 50. 52. 53.]]
```

从生成的$8\times 12$的矩阵中可以观察到：

- 前4行是样本1的数据，后4行是样本2的数据
- 前4列是通道1的数据，中间4列是通道2的数据，后4列是通道3的数据

#### 权重数组的展开

对应的四维输入数据，卷积核权重数组也需要是四维的，其原始形状和展开后的形状如下：
```
weights=
(过滤器1)               (过滤器2)
    (卷积核1)               (卷积核1)
 [[[[ 0  1]             [[[12 13]
   [ 2  3]]               [14 15]]
    (卷积核2)               (卷积核2)
  [[ 4  5]               [[16 17]
   [ 6  7]]               [18 19]]
    (卷积核3)               (卷积核3)
  [[ 8  9]               [[20 21]
   [10 11]]]              [22 23]]]]
---------------------------------------
col_w=
 [[ 0 12]
  [ 1 13]
  [ 2 14]
  [ 3 15]
  [ 4 16]
  [ 5 17]
  [ 6 18]
  [ 7 19]
  [ 8 20]
  [ 9 21]
  [10 22]
  [11 23]]
```

至此，展开数组已经可以和权重数组做矩阵相乘了。

#### 结果数据的处理

原始数据展开成了$8\times 12$的矩阵，权重展开成了$12\times 2$的矩阵，所以最后的结果是$8\times 2$的矩阵：
```
[[1035.| 2619.]
 [1101.| 2829.]
 [1233.| 3249.]
 [1299.| 3459.]
 ------+-------
 [2817.| 8289.]
 [2883.| 8499.]
 [3015.| 8919.]
 [3081.| 9129.]]
```
这是两个样本的结果。如何把它拆开呢？是简单的左右分开就行了吗？这里要稍微动一下脑筋，推理一下：

1. 两个样本的原始数组x展开后的矩阵`col_x`是$8\times 12$，计算结果是$8\times 2$，如果原始数据只有一个样本，则展开矩阵`col_x`的形状是$4\times 12$，那么运算结果将会是$4\times 2$。所以，在上面这个$8\times 2$的矩阵中，前4行应该是第一个样本的卷积结果，后4行是第二个样本的卷积结果。
2. 如果输出通道只有一个，则权重矩阵`w`展开后的`col_w`只有一列，那么运算结果将会是$8\times 1$；两个输出通道的运算结果是$8\times 2$。所以第一列和第二列应该是两个通道的数据，而不是两个样本的数据。

也就是说，在这个数组中：

- 第1列的前4行是第1个样本的第1个通道的输出
- 第2列的前4行是第1个样本的第2个通道的输出
- 第1列的后4行是第2个样本的第1个通道的输出
- 第2列的后4行是第2个样本的第2个通道的输出

于是我们可以分两步得到正确的矩阵形状：

<font color=green> 这里需要对输出通道的概念做一个说明，根据Section 17.1的图17.16，就是可以知道，这个输出通道的意思，就是输出feature的意思，每一个feature的输出，就是对应的是每一个filter的输出。</font>

1. 先把数据变成2个样本 * 输出高度 * 输出宽度的形状：

```Python
out2 = output.reshape(batch_size, output_height, output_width, -1)
```

得到结果：

```
out2= 
[[[[1035. 2619.]
   [1101. 2829.]]
  [[1233. 3249.]
   [1299. 3459.]]]
 [[[2817. 8289.]
   [2883. 8499.]]
  [[3015. 8919.]
   [3081. 9129.]]]]
```

注意现在1035和2619在一个子矩阵中，这是不对的，因为它们应该属于两个通道，所以应该在两个子矩阵中。目前这个结果中的四维数据的顺序是：样本、行、列、通道。于是我们做第二步，把“通道”所在的第4维移到第2维，变成：样本、通道、行、列：

2. 把第4维数据放到第2维（由于是0-base的，所以是把第3维移到第1维的位置）：

```Python
out3 = np.transpose(out2, axes=(0, 3, 1, 2))
```

<font color=red> ToDo: 我明白上面这个还是需要再做一个转换，但是对这个transpose的实现方式还是有点陌生，主要还是维度的原因，之前在编写代码的时候，始终是对这个多维度的概念是有点模糊不清，比如说就是有多个方括号，不太清楚其物理含义，现在经过Section 17的学习之后，我现在对这个Python中的多个方括号的概念已经是有一定的了解的了。---->

在理解这个transpose的代码的时候，需要结合输入out2和输出out3来做对比；比如说，在out2中，第一个中括号代表的是样本数，此时[[[1035. 2619.] [1101. 2829.]] [[1233. 3249.] [1299. 3459.]]]代表的是一个样本（维度）；然后[[[2817. 8289.] [2883. 8499.]] [[3015. 8919. [3081. 9129.]]]代表的是另外一个样本（维度）；而通过比对out3中的放括弧&数据，具体的数字都是一致的；

在out2中，第二个中括号代表的是行；所以[[1035. 2619.] [1101. 2829.]]代表一“行”；[[1233. 3249.] [1299. 3459.]]代表另外一“行”。实际上，从人可以理解的角度来看，1035. 1233.是一个维度的数据，2619. 3249.另外一个维度的数据

在out2中，第三个中括号代表的是列；所以[1035. 2619.]；[1101. 2829.]；[1233. 3249.] [1299. 3459.]都是代表各自一“列”的数据。类似的，实际上，从人可以理解的角度来看，1035. 1101.是一个维度的数据，2619. 2829.是另一个维度的数据

在out2中，第四个中括号代表的是通道；所以1035.是一个通道的数据，2619.是另外一个通道的数据
</font>

结果是：

```
conv result=
(样本1)                     (样本2)
    (通道1)                     (通道1)
 [[[[1035. 1101.]            [[[2817. 2883.]
   [1233. 1299.]]              [3015. 3081.]]
    (通道2)                     (通道2)
  [[2619. 2829.]              [[8289. 8499.]
   [3249. 3459.]]]             [8919. 9129.]]]]
```

#### 验证正确性

我们可以用17.2.3中的方法1做为基准，如果用本节中的方法3可以得到同样的结果，就说明这种方式是正确的。

```Python
def test_4d_im2col():
    ......
    f1 = c1.forward_numba(x)
    f2 = c1.forward_img2col(x)
    print("correctness:", np.allclose(f1, f2, atol=1e-7))
```
得到的结果是：
```
correctness: True
```
上面的代码，首先生成了一个`ConvLayer`实例，然后分别调用内部实现的`forward_numba()`方法和`forward_img2col()`方法，得到`f1`和`f2`两个卷积结果矩阵，然后比较其数值，最后的返回值为`True`，说明`im2col`方法的正确性。

#### 性能测试

下面我们比较一下方法2和方法3的性能。

```Python
def test_performance():
    ...
    print("compare correctness of method 1 and method 2:")
    print("forward:", np.allclose(f1, f2, atol=1e-7))
```

上述代码先生成一个`ConvLayer`实例，然后分别调用1000次`forward_numba()`方法和1000次`forward_img2col()`方法，最后得到的结果是：

```
method numba: 11.663846492767334
method img2col: 14.926148653030396
compare correctness of method 1 and method 2:
forward: True
```

`numba`方法会比`im2col`方法快3秒，目前看来`numba`方法稍占优势。但是如果没有`numba`的帮助，`im2col`方法会比方法1快几百倍。

### 代码位置

ch17, Level2

其中，`Level2_Numba_Test.py`是测试`numba`库的性能，`Level2_Img2Col_Test`是比较`numba`方法和`im2col`方法的前向计算性能。

在Level2的主过程中有4个函数：

- `test_2d_conv`，理解2维下`im2col`的工作原理
- `understand_4d_im2col`，理解4维下`im2col`的工作原理
- `test_4d_im2col`，比较两种方法的结果，从而验证正确性
- `test_performance`，比较两种方法的性能



<font color=green> 这里需要注意一下的是，在本文的solution 1 & solution 2的方案中，则是使用了维度遍历的方式，进行就和的操作；

但是对于本section的Solution 3来说，因为方法特殊性（比如说使用的矩阵相乘，就是可以自动的完成这个前面三个feature的求和操作了。

方案三的红字部分，就是有对这个高维度数据的理解（从数据本身的角度），如果对高维度的数据不太熟悉的话，就是可以再过来看一遍
</font>