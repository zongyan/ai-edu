<!--Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可-->

## 14.2 回归任务 - 房价预测

### 14.2.1 数据

数据集来自：https://www.kaggle.com/harlfoxem/housesalesprediction

此数据集是King County地区2014年五月至2015年五月的房屋销售信息，适合于训练回归模型。

#### 数据字段解读

- id：唯一id
- date：售出日期
- price：售出价格（标签值）
- bedrooms：卧室数量
- bathrooms：浴室数量
- sqft_living：居住面积
- sqft_lot：停车场面积
- floors：楼层数
- waterfront：泳池
- view：有多少次看房记录
- condition：房屋状况
- grade：评级
- sqft_above：地面上的面积
- sqft_basement：地下室的面积
- yr_built：建筑年份
- yr_renovated：翻修年份
- zipcode：邮政编码
- lat：维度
- long：经度
- sqft_living15：2015年翻修后的居住面积
- sqft_lot15：2015年翻修后的停车场面积

一些考虑：

- 唯一id在数据库中有用，在训练时并不是一个特征，所以要去掉
- 售出日期，由于是在一年内的数据，所以也没有用
- sqft_liging15的值，如果非0的话，应该替换掉sqft_living
- sqft_lot15的值，如果非0的话，应该替换掉sqft_lot
- 邮政编码对应的地理位置过于宽泛，只能引起噪音，应该去掉
- 返修年份，笔者认为它如果是非0值的话，可以替换掉建筑年份
- 看房记录次数多并不能代表该房子价格就高，而是因为地理位置、价格、配置等满足特定人群的要求，所以笔者认为它不是必须的特征值

所以最后只留下13个字段。<font color=green> 这个数据集，就是比之前我做的另外一个regression tutorial还是要复杂一些（input features的数量要多很多）。不过，这里也是提到了一个很重要的问题，就是这个input feature怎么选择，应该是怎么选择，这个倒是只能够问domain expert了。</font>

#### 数据处理

原始数据只有一个数据集，所以需要我们自己把它分成训练集和测试集，比例大概为4:1。此数据集为`csv`文件格式，为了方便，我们把它转换成了两个扩展名为`npz`的`numpy`压缩形式：

- `house_Train.npz`，训练数据集
- `house_Test.npz`，测试数据集

<font color=green> See section 9.3，就是可以找到各种数据集之间的比例关系了。</font>

<font color=red> ToDo: 是不是对于数据本身来说，就是最好先是把数据的根数处理一下，分成训练数据集，和测试数据集，然后就是用npz的形式保存，然后在这个训练数据集里面，再进一步拆分出一个验证数据集呢。--> 根据这个下面一段的文字描述，我的这个总结是正确的。</font>

#### 加载数据

与上面第一个例子的代码相似，但是房屋数据属性繁杂，所以需要做归一化，房屋价格也是至少6位数，所以也需要做归一化。

这里有个需要注意的地方，即训练集和测试集的数据，需要合并在一起做归一化，然后再分开使用。为什么要先合并呢？假设训练集样本中的房屋面积的范围为150到220，而测试集中的房屋面积有可能是160到230，两者不一致。分别归一化的话，150变成0，160也变成0，这样预测就会产生误差。

最后还需要在训练集中用`GenerateValidaionSet(k=10)`分出一个1:9的验证集。

### 14.2.2 搭建模型

在不知道一个问题的实际复杂度之前，我们不妨把模型设计得复杂一些。如下图所示，这个模型包含了四组全连接层-Relu层的组合，最后是一个单输出做拟合。

<img src="../Images/14/non_linear_regression.png" />

图14-5 完成房价预测任务的抽象模型

<font color=green> 在Section 11.2中，就是可以看到，这个神经元的个数是按照如下的顺序进行增加测试的：2，4，8，16，32，64。所以这里就是按照这一种节奏顺序增加，某种程度上也是有一定的可借鉴性。比如说，因为输入层是13个features，所以就是会选择32个神经元，之所以不选择，因为是担心16个不够，因为太接近13这个数字的了。但这个也不是绝对的，也是需要经过后天的训练决定的。这个就是我的一些粗浅的分析。</font> <font color=red> 至于这其中是不是有什么理论支撑，还是凭借着经验而已，这个就是只能够留给以后来作答了。</font> <font color=red> 另外，为什么是使用ReLU这个激活函数，我就是真得是需要查阅资料了，就是需要搞清楚，什么情况下，就是选择哪一种得激活函数。</font>

<font color=red> 参见Section 14.6，上面的内容不全对，因为也是出现例外了。</font>

```Python
def model():
    dr = LoadData()

    num_input = dr.num_feature
    num_hidden1 = 32
    num_hidden2 = 16
    num_hidden3 = 8
    num_hidden4 = 4
    num_output = 1

    max_epoch = 1000
    batch_size = 16
    learning_rate = 0.1

    params = HyperParameters_4_0(
        learning_rate, max_epoch, batch_size,
        net_type=NetType.Fitting,
        init_method=InitialMethod.Xavier,
        stopper=Stopper(StopCondition.StopDiff, 1e-7))

    net = NeuralNet_4_0(params, "HouseSingle")

    fc1 = FcLayer_1_0(num_input, num_hidden1, params)
    net.add_layer(fc1, "fc1")
    r1 = ActivationLayer(Relu())
    net.add_layer(r1, "r1")
    ......
    fc5 = FcLayer_1_0(num_hidden4, num_output, params)
    net.add_layer(fc5, "fc5")

    net.train(dr, checkpoint=10, need_test=True)
    
    output = net.inference(dr.XTest)
    real_output = dr.DeNormalizeY(output)
    mse = np.sum((dr.YTestRaw - real_output)**2)/dr.YTest.shape[0]/10000
    print("mse=", mse)
    
    net.ShowLossHistory()

    ShowResult(net, dr)
```

超参数说明：

1. 学习率=0.1
2. 最大`epoch=1000`
3. 批大小=16
4. 拟合网络
5. 初始化方法Xavier
6. 停止条件为相对误差`1e-7`

net.train()函数是一个阻塞函数，只有当训练完毕后才返回。

在train后面的部分，是用测试集来测试该模型的准确度，使用了数据城堡(Data Castle)的官方评测方法，用均方差除以10000，得到的数字越小越好。一般的模型大概是一个7位数的结果，稍微好一些的是6位数。<font color=green> 数据城堡就是一个大数据培训和竞赛平台，类似于kaggle的一个平台，只要知道这个平台，还有这个参数就是可以的了。虽然是没有仔细的研究，但是感觉就是类似于这个GPU的跑分一样，就是一个ranking而已。</font>

### 14.2.3 训练结果

<img src="../Images/14/house_loss.png" />

图14-6 训练过程中损失函数值和准确率的变化

由于标签数据也做了归一化，变换为都是0至1间的小数，所以均方差<font color=green>(mean squared error)</font>的数值很小，需要观察小数点以后的第4位。从图14-6中可以看到，损失函数值很快就降到了0.0002以下，然后就很缓慢地下降。而精度值在不断的上升，相信更多的迭代次数会带来更高的精度。

再看下面的打印输出部分，用R2_Score法得到的值为0.841，而用数据城堡官方的评测标准，得到的MSE值为2384411，还比较大，说明模型精度还应该有上升的空间。<font color=green> 根据下面这个$R_{2}$的定义，得到的这个结果还是不错的。</font>

```
......
epoch=999, total_iteration=972999
loss_train=0.000079, accuracy_train=0.740406
loss_valid=0.000193, accuracy_valid=0.857289
time used: 193.5549156665802
testing...
0.8412989144927305
mse= 2384411.5840510926
```

### 代码位置

ch14, Level2 <font color=red> ToDo: 虽然原始数据是没有提供，但是还是需要把代码过一下的。--> 后来就是发现，有一个链接，是可以直接下载数据的，然后的呢，就是有另外数据处理文件，是可以处理下载下来的数据的，也就是说，数据的问题，在这个section里面，是已经解决了。</font>

<font color=green> 
其实，除了这个loss & accuracy，即图14.6可以借鉴之外，另外还有两个数据，就是在regression的问题中也是非常的有用的，一个就是R2的数值，另外一个就是精度的图，如下所示（即图是14.4右侧的图）

<img src="../Images/14/Figure 2021-05-19 221944.png" /> 

以测试集的真实值为横坐标，以真实值和预测值的差为纵坐标。最理想的情况是所有点都在y=0处排成一条横线。

</font>

<font color=green> 


均方差(mean square error)的表达方式如下：

$$ \frac{1}{N}\sum_{i=1}^{N}(y_i-\hat{y}_i) $$

标准差(standard deviation)的表达式如下：

$$ \sqrt{\frac{1}{N}\sum_{i=1}^{N}(y_i-\bar{y}_i)} $$

其实，两者的差别不大，对于均方差来说，使用的是observed values - actual values；但是呢，对于这个标准差来说，使用的是values - mean value。从这两个公式来看，两者也是有很大的区别的
</font>

<font color=green> 
R2_Score(coefficient of determination, pronounced "R squared"), 下面的这张图，就是给出了这个R2的定义：

The coefficient of determination is the proportion of the variance in the dependent variable that is predictable from the independent variable(s)

<img src="../Images/14/DefinitionsR2.png" />

再补充说明一下，最好的情况就是$R^{2}$等于1，此时$SS_{res}$是等于0，也就说observered value就是和actual value是一样的。然后base line就是predicted value总是等于这个均值，然后此时$R_{2}$是等于0；然后接着再差的情况，这个$R_{2}$就是一个负数了。

另外，R2用在回归问题。
</font>
