<!--Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可-->

# 第十步  个人总结

这个文本的作用，是为以后自己从事人工神经网络的开发做一个备忘录，可以起到快速定位本书内容的作用。

## 知识点解释

1. 关FeedForward Neural Network (FFNN) & CNN中反向传播的误差矩阵&梯度矩阵的计算，参见Section 9.4, 14.1 and 17.3，其实计算误差矩阵，主要目的就是为了辅助计算梯度矩阵。
2. Section 7.1 & 7.2是关于（线性）多分类神经网络正向传播&反向传播的介绍，主要针对的就是softmax多分类函数了。以及Section 3.0, 3.2, 19.5给出了softmax和交叉熵损失函数的关系，以及交叉熵损失函数＆均方差损失函数的区别
3. 在看完LSTM的基本原理（Section 20.1）的内容之后，突然就是明白了，在反向传播的过程中（dnn, rnn & cnn），先是把相应的误差矩阵计算出来，然后就是可以根据误差矩阵，计算出相应的梯度矩阵了，然后这一些梯度矩阵就是可以用来调整weights & biases了。


## 代码示例

### 数据处理代码示例

1. 定时间步RNN需要的数据（从初始的csv到后来的numpy array格式），可以参见Section 19.4相关的内容（ch19, Level4）。Data文件夹中的代码（ch19_PM25.py），就是给出了一个很好的例子（即从csv到最后的numpy's array）。同时呢，PM25DataReader.py里面的Normalize function也是给出了从二维的数据到三维的数据的示例---缺失值、累计值处理，具体的方式可以debug ch19-Level4的代码即可（为了节省时间，需要把max_epoch，时间步长【定义网络时候】调小）。
2. 不定时间步RNN的数据（从txt到numpy array格式），可以参见Section 19.5的相关内容（ch19, Level5）。NameDataReader.py给出了详细的过程，比如读取txt文档，使用try-except-finally，toOneHot的转换，以及list&array的混合使用等。具体的方式可以debug ch19-Level4的代码即可（为了节省时间，需要把max_epoch调小）。
3. ToDo: 读取image数据
4. Section 19.7 使用(单向或双向)rnn，以及MNIST的数据进行训练的时候。原始的数据的维度是$128*1*28*28$（128是batch size），在喂给神经网络进行训练的时候，重新把数据的维度变成了$128*28*28$，这样子，定义rnn网络的时候，时间步也就是28了（另外，此时$128*28*28$的中间一个维度，既可以认为是时间步，也是可以认为是image的width）。参见ch19-Level7的代码给出如何将image数据变成适合rnn的数据（即前一句话提到的维度变化【从四维变成三维】）。----但是，MNIST是灰色的，如果是彩色的，维度变换的时候还是需要注意的。

Note: 以上的内容，不仅仅是局限于RNN，也许对其他类型的网络也是有很大的帮助的。


### 神经网络创建&训练代码示例

1. ch18的代码文件夹里面有基于PyTorch的CNN代码示例，可以借鉴使用的（不过可能由于我的本地配置torchvision的问题，暂时没有办法正常运行起来）
2. ```from tqdm import tqdm```可以用来显示for循环的进度
3. Sections 19.4 & 19.6中的保存最小值loss的代码，就是有极大的好处的了，可以避免重复训练的一个烦恼了。（19.4节有较为详细的comment，19.4&19.6节这部分的代码，其实都是一样的。）
4. Section 19.4 & 19.6解释RNN预测未来数据的逻辑



### 图片plot代码示例

1. 画1x2（或者类似）的图片，可以参见TrainingHistory_3_0.py中的ShowLossHistory函数，同时呢，HyperParameters_4_3.py的toString函数也是给出了title的便捷方式了。具体的方式可以debug ch19-level4的代码即可（运行代码的时候，请把line 54的num_step设置为4，可以加快debug的速度） 
2. 混淆矩阵（confusion matrix）的一个很好的应用，就似乎在多分类的问题中，可以让结果变得一目了然。Section 19.5 以及ch19-level5是一个很好的例子
